{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "fitsfiles = [] \n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles'):\n",
    "    for file in filenames:    \n",
    "        if(file.endswith('.fits')):\n",
    "            if('pfss_intoout' in file):\n",
    "                fitsfiles.append((dirpath + '/' + file, 'PFSS_IO'))\n",
    "            elif('pfss_outtoin' in file):\n",
    "                fitsfiles.append((dirpath + '/' + file, 'PFSS_OI'))\n",
    "            elif('scs_outtoin' in file):\n",
    "                fitsfiles.append((dirpath + '/' + file, 'SCS_OI'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintion from OpenSpace function FieldlinesState::saveStateToOsfls\n",
    "    File is structured like this: (for version 0)\n",
    "    0. int                    - version number of binary state file! (in case something needs to be altered in the future, then increase CurrentVersion)\n",
    "    1. double                 - _triggerTime\n",
    "    2. int                    - _model\n",
    "    3. bool                   - _isMorphable\n",
    "    4. size_t                 - Number of lines in the state  == _lineStart.size() == _lineCount.size()\n",
    "    5. size_t                 - Total number of vertex points  == _vertexPositions.size() == _extraQuantities.size()\n",
    "    6. size_t                 - Number of extra quantites  == _extraQuantities.size() == _extraQuantityNames.size()\n",
    "    7. site_t                 - Number of total bytes that ALL _extraQuantityNames  consists of (Each such name is stored as a c_str which means it ends with the null char '\\0' )\n",
    "    8. std::vector<GLint>     - _lineStart\n",
    "    9. std::vector<GLsizei>   - _lineCount\n",
    "    10. std::vector<glm::vec3> - _vertexPositions\n",
    "    11. std::vector<float>     - _extraQuantities\n",
    "    12. array of c_str         - Strings naming the extra quantities (elements of _extraQuantityNames). Each string ends with null char '\\0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, numpy\n",
    "\n",
    "def sph2cart(coord):\n",
    "    return [\n",
    "         coord[2] * math.sin(coord[1]) * math.cos(coord[0]), \n",
    "         coord[2] * math.sin(coord[1]) * math.sin(coord[0]),\n",
    "         coord[2] * math.cos(coord[1])\n",
    "    ]\n",
    "\n",
    "def coord2datarow(coord):\n",
    "    sph = sph2cart(coord[0:3])\n",
    "    sph.append(coord[5])\n",
    "    return [numpy.float32(x) for x in sph] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Model(Enum):\n",
    "    Batsrus = 0\n",
    "    Enlil = 1\n",
    "    Pfss = 2\n",
    "    Wsa = 3\n",
    "    Invalid = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstimeToJ2000(ot):\n",
    "    timefits = ot[0:4] + '-' + ot[5:7] + '-' + ot[8:10] + 'T'\n",
    "    timefits += ot[11:13] + ot[14:17] + ot[18:21] + '.000'\n",
    "    pathSafeTimeString = timefits.replace(':', '-')\n",
    "    time = Time(timefits, format='fits')\n",
    "    y2000 = Time(2000, format='jyear')\n",
    "    jdaysdelta = time.jd - y2000.jd\n",
    "    jsecs = jdaysdelta*60*60*24\n",
    "    return [jsecs, pathSafeTimeString]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import struct, ctypes, math\n",
    "\n",
    "def toOsfls(filename, modelname, indices,  typename, xq_filename = \"\"):\n",
    "    fl_fits = fits.open(filename)\n",
    "    fl_data = fl_fits[0].data\n",
    "    fl_fits.close()\n",
    "    \n",
    "    # read file for extra quantity\n",
    "    if(modelname != 'PFSS_IO'):\n",
    "        vel_fits = fits.open(xq_filename)\n",
    "        vel_data = vel_fits[0].data\n",
    "        vel_data = vel_data[1] # the second layer has the wind speed\n",
    "        vel_fits.close()\n",
    "        \n",
    "    \n",
    "    \n",
    "    versionNumber = 0\n",
    "    [triggerTime, pathSafeTimeString] = obstimeToJ2000(fl_fits[0].header['OBSTIME'])\n",
    "    #print(\"TriggerTime: \",triggerTime)\n",
    "    print(\"pathSafeTimeString: \",pathSafeTimeString)\n",
    "    fileName = pathSafeTimeString + '.osfls'\n",
    "\n",
    "    model = Model.Wsa.value\n",
    "    isMorphable = False\n",
    "\n",
    "    nVert = 0\n",
    "    lineStart = []\n",
    "    lineCount = []\n",
    "    vertexPositions = []\n",
    "    extraQuantities = []\n",
    "\n",
    "    for i in indices:\n",
    "        points = [coord2datarow(pt) for pt in fl_data[i] if pt[0] > -900] \n",
    "        if (len(points) < 2): continue\n",
    "        lineStart.append(nVert)\n",
    "        nVert += len(points)\n",
    "        lineCount.append(len(points))\n",
    "        [vertexPositions.extend(pt[0:3]) for pt in points] # extend to unfold elements\n",
    "        if(modelname == 'PFSS_IO'):\n",
    "            [extraQuantities.append(pt[3]) for pt in points]\n",
    "        else:     \n",
    "            velocity = vel_data[math.floor(i/180)][i%180]\n",
    "            if(points[0][3] < 0): velocity = -1*velocity\n",
    "            xtra = [velocity]*len(points) # same value for all points\n",
    "            extraQuantities.extend(xtra)\n",
    "    \n",
    "    nLines = len(lineStart)\n",
    "\n",
    "    nExtras = 1\n",
    "    if(modelname == 'PFSS_IO'):\n",
    "        extraQuantityNames = ['b-field radius \\0']\n",
    "    else: \n",
    "        extraQuantityNames = ['wind speed with polarity \\0']\n",
    "    nStringBytes = sum([len(s) for s in extraQuantityNames])\n",
    "    allNamesInOne = ''\n",
    "    for s in extraQuantityNames:\n",
    "        allNamesInOne += s\n",
    "    \n",
    "    # Prepare data for writing to binary. Using Struct and pack\n",
    "    typestr = '= i d i ? Q Q Q Q %sl %sL %sf %sf %ss' % (nLines, nLines, 3*nVert, nVert, nStringBytes)\n",
    "    struct_to_write = struct.Struct(typestr)\n",
    "    #print('Format string  :', struct_to_write.format)\n",
    "    print('Uses           :', struct_to_write.size, 'bytes')\n",
    "    values_to_write = (versionNumber, triggerTime, model, isMorphable, nLines, nVert, nExtras, nStringBytes)\n",
    "    values_to_write += (*lineStart, *lineCount, *vertexPositions, *extraQuantities, allNamesInOne.encode('utf-8'))\n",
    "    \n",
    "    buffer = ctypes.create_string_buffer(struct_to_write.size)    \n",
    "    struct_to_write.pack_into(buffer, 0, *values_to_write)\n",
    "    \n",
    "    fout = open('./' + modelname + '/' + typename + '_' + fileName, 'wb')\n",
    "    fout.write(buffer)\n",
    "    fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make into osfls format - every nth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everynth(step):\n",
    "    return (range(0,16200, step), 'step' + str(step))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "indices = everynth(25)\n",
    "\n",
    "for fitsfile in fitsfiles:\n",
    "    toOsfls(fitsfile[0], fitsfile[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(fitsfile[0],time.time()-start_time))\n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only PFSS_IO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathSafeTimeString:  2019-05-02T08-00-00.000\n",
      "Uses           : 354816 bytes\n",
      "Finished converting PFSS_IO after 0.8480010032653809 seconds.\n",
      "pathSafeTimeString:  2019-05-02T12-00-00.000\n",
      "Uses           : 346232 bytes\n",
      "Finished converting PFSS_IO after 1.6761369705200195 seconds.\n",
      "pathSafeTimeString:  2019-05-02T18-00-00.000\n",
      "Uses           : 359056 bytes\n",
      "Finished converting PFSS_IO after 2.592864990234375 seconds.\n",
      "pathSafeTimeString:  2019-05-02T14-00-00.000\n",
      "Uses           : 351032 bytes\n",
      "Finished converting PFSS_IO after 3.518928050994873 seconds.\n",
      "pathSafeTimeString:  2019-05-02T16-00-00.000\n",
      "Uses           : 353016 bytes\n",
      "Finished converting PFSS_IO after 4.318600177764893 seconds.\n",
      "pathSafeTimeString:  2019-05-02T20-00-00.000\n",
      "Uses           : 360432 bytes\n",
      "Finished converting PFSS_IO after 5.060018301010132 seconds.\n",
      "pathSafeTimeString:  2019-05-02T10-00-00.000\n",
      "Uses           : 352000 bytes\n",
      "Finished converting PFSS_IO after 5.903692960739136 seconds.\n",
      "Execution time for type step13: 5.9038472175598145 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# relies heavily on having a sorted list of files for each timestep\n",
    "# so that pfss_io goes first and picks out the lines\n",
    "for timestamp in fitsfilesdates:\n",
    "    fitsfilesdates[timestamp].sort()\n",
    "    pfss_io = fitsfilesdates[timestamp][0]\n",
    "    indices = everynth(13)\n",
    "    toOsfls(pfss_io[0], pfss_io[1], indices[0], indices[1], wsafilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_io[1],time.time()-start_time))\n",
    "    \n",
    "        \n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick closed field lines from PFSS_IO\n",
    "By removing the open ones. Opens ones are defined by their first and last point having the same polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickClosed(filename):\n",
    "    fl_fits = fits.open(filename)\n",
    "    fl_data = fl_fits[0].data\n",
    "\n",
    "    indices_to_save = []\n",
    "\n",
    "    for i in range(16200):\n",
    "        b_radii = [pt[5] for pt in fl_data[i] if pt[0] > -900] \n",
    "        if (len(b_radii) < 2): continue\n",
    "        first_b_radius = b_radii[0]\n",
    "        last_b_radius = b_radii[-1]\n",
    "        if(first_b_radius*last_b_radius < 0): #if product is negative/opposite signs\n",
    "            indices_to_save.append(i)\n",
    "    return indices_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pfss_io closed lines sparser\n",
    "def make_sparser(indices, step):\n",
    "    new_indices = indices[::3]\n",
    "    return [new_indices, 'closed_step' + str(step)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick boundary lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def boundaryLines(filename_io, filename_oi, indices_closed):\n",
    "    fl_io = (fits.open(filename_io))[0].data\n",
    "    fl_oi = (fits.open(filename_oi))[0].data\n",
    "\n",
    "    threshold = math.sqrt(2)\n",
    "    # boundary_lines_io = [] do we want these?\n",
    "    boundary_lines_oi = []\n",
    "    io_last_phi = {}\n",
    "    io_last_theta = {}\n",
    "    io_first_phi = {}\n",
    "    io_first_theta = {}\n",
    "\n",
    "    for j in indices_closed:\n",
    "        last = -1 # find last index\n",
    "        for point in fl_io[j]:\n",
    "            if (point[0] > -900):\n",
    "                last += 1\n",
    "            else: break\n",
    "        # get the first and last coordinates for in-to-out (both on surface)\n",
    "        io_last_phi[j] = math.degrees(fl_io[j][last][0])\n",
    "        io_last_theta[j] = math.degrees(fl_io[j][last][1])\n",
    "        io_first_phi[j] = math.degrees(fl_io[j][0][0])\n",
    "        io_first_theta[j] = math.degrees(fl_io[j][0][1])\n",
    "\n",
    "    for i in range(16200):\n",
    "        last = -1\n",
    "        for point in fl_oi[i]:\n",
    "            if (point[0] > -900):\n",
    "                last += 1\n",
    "            else: break\n",
    "        if (last < 2): continue\n",
    "        # get the last coordinates for out-to-in (the ones on the surface)\n",
    "        oi_last_phi = math.degrees(fl_oi[i][last][0])\n",
    "        oi_last_theta = math.degrees(fl_oi[i][last][1])\n",
    "        for j in indices_closed:\n",
    "            # calculate distances and compare\n",
    "            dist_last_phi = abs(io_last_phi[j] - oi_last_phi)\n",
    "            dist_last_theta = abs(io_last_theta[j] - oi_last_theta)\n",
    "            dist_first_phi = abs(io_first_phi[j] - oi_last_phi)\n",
    "            dist_first_theta = abs(io_first_theta[j] - oi_last_theta)\n",
    "            if(dist_last_phi < threshold and dist_last_theta < threshold):\n",
    "                #boundary_lines_io.append(j)\n",
    "                boundary_lines_oi.append(i)\n",
    "                break\n",
    "            if(dist_first_phi < threshold and dist_first_theta < threshold):\n",
    "                #boundary_lines_io.append(j)\n",
    "                boundary_lines_oi.append(i)\n",
    "                break\n",
    "    return [boundary_lines_oi, 'boundary']\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate file list based on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsfilesdates = {} \n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles'):\n",
    "    for file in filenames:    \n",
    "        if(file.endswith('.fits')):\n",
    "            date = file[0:12]\n",
    "            if(date not in fitsfilesdates):\n",
    "                fitsfilesdates[date] = []\n",
    "            if('pfss_intoout' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'PFSS_IO'))\n",
    "            elif('pfss_outtoin' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'PFSS_OI'))\n",
    "            elif('scs_outtoin' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'SCS_OI'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "velfilesdates = {}\n",
    "wsafilesdates = {}\n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles_images'):\n",
    "    for file in filenames:    \n",
    "        if('vel' in file):\n",
    "            date = file[4:16]\n",
    "            velfilesdates[date] = dirpath + '/' + file\n",
    "        if('wsa' in file):\n",
    "            date = file[4:16]\n",
    "            wsafilesdates[date] = dirpath + '/' + file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill out those boundary lines\n",
    "With some sparse lines in between"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOut(boundary_indices, step):\n",
    "    output = []\n",
    "    previous_index = 0\n",
    "    for index in boundary_indices:\n",
    "        subrange = list(range(previous_index, index, step))\n",
    "        output.extend(subrange)\n",
    "        if(output[-1] != index):    \n",
    "            output.append(index)\n",
    "        previous_index = index\n",
    "    return [output, 'boundary_filled']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make into osfls - closed lines and boundary lines with fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Picked closed lines for 201905020800 after 1.5125329494476318 seconds.\n",
      "Finished converting PFSS_IO after 1.5126447677612305 seconds.\n",
      "Picked boundary lines after 51.77428603172302 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T08-00-00.000\n",
      "Uses           : 7573171 bytes\n",
      "Finished converting PFSS_OI after 54.353524923324585 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T08-00-00.000\n",
      "Uses           : 9476243 bytes\n",
      "Finished converting SCS_OI after 58.040857791900635 seconds.\n",
      "Picked closed lines for 201905021200 after 61.26558303833008 seconds.\n",
      "Finished converting PFSS_IO after 61.26574778556824 seconds.\n",
      "Picked boundary lines after 118.85041189193726 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T12-00-00.000\n",
      "Uses           : 7403011 bytes\n",
      "Finished converting PFSS_OI after 121.37582683563232 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T12-00-00.000\n",
      "Uses           : 9327203 bytes\n",
      "Finished converting SCS_OI after 125.12558197975159 seconds.\n",
      "Picked closed lines for 201905021600 after 128.2734899520874 seconds.\n",
      "Finished converting PFSS_IO after 128.27363991737366 seconds.\n",
      "Picked boundary lines after 187.6009168624878 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T16-00-00.000\n",
      "Uses           : 7618171 bytes\n",
      "Finished converting PFSS_OI after 190.58340787887573 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T16-00-00.000\n",
      "Uses           : 9634971 bytes\n",
      "Finished converting SCS_OI after 194.920578956604 seconds.\n",
      "Picked closed lines for 201905022000 after 197.8375449180603 seconds.\n",
      "Finished converting PFSS_IO after 197.83780193328857 seconds.\n",
      "Picked boundary lines after 257.722060918808 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T20-00-00.000\n",
      "Uses           : 7698811 bytes\n",
      "Finished converting PFSS_OI after 260.4457468986511 seconds.\n",
      "(90, 180)\n",
      "pathSafeTimeString:  2019-05-02T20-00-00.000\n",
      "Uses           : 9674299 bytes\n",
      "Finished converting SCS_OI after 264.4461119174957 seconds.\n",
      "Execution time for type boundary_filled: 264.44628977775574 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# relies heavily on having a sorted list of files for each timestep\n",
    "# so that pfss_io goes first and picks out the lines\n",
    "for timestamp in fitsfilesdates:\n",
    "    fitsfilesdates[timestamp].sort()\n",
    "    pfss_io = fitsfilesdates[timestamp][0]\n",
    "    pfss_oi = fitsfilesdates[timestamp][1]\n",
    "    scs_oi = fitsfilesdates[timestamp][2]\n",
    "    indices_closed_lines = pickClosed(pfss_io[0])\n",
    "    print('Picked closed lines for {} after {} seconds.'.format(timestamp,time.time()-start_time))\n",
    "    indices = make_sparser(indices_closed_lines, 3) # change here for sparser\n",
    "    toOsfls(pfss_io[0], pfss_io[1], indices[0], indices[1], wsafilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_io[1],time.time()-start_time))\n",
    "    indices = boundaryLines(pfss_io[0], pfss_oi[0], indices_closed_lines)\n",
    "    indices = fillOut(indices[0], 25) # change step here for sparser\n",
    "    print('Picked boundary lines after {} seconds.'.format(time.time()-start_time))\n",
    "    toOsfls(pfss_oi[0], pfss_oi[1], indices[0], indices[1], velfilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_oi[1],time.time()-start_time))\n",
    "    toOsfls(scs_oi[0], scs_oi[1], indices[0], indices[1], velfilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(scs_oi[1],time.time()-start_time))\n",
    "        \n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the last 540 (sun-earth connection)\n",
    "And turn OI sets to osfls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pathSafeTimeString:  2019-05-02T08-00-00.000\n",
      "Uses           : 1588363 bytes\n",
      "Finished converting PFSS_OI after 0.6377420425415039 seconds.\n",
      "pathSafeTimeString:  2019-05-02T08-00-00.000\n",
      "Uses           : 1908619 bytes\n",
      "Finished converting SCS_OI after 1.3328490257263184 seconds.\n",
      "pathSafeTimeString:  2019-05-02T12-00-00.000\n",
      "Uses           : 1594235 bytes\n",
      "Finished converting PFSS_OI after 1.9223661422729492 seconds.\n",
      "pathSafeTimeString:  2019-05-02T12-00-00.000\n",
      "Uses           : 1941995 bytes\n",
      "Finished converting SCS_OI after 2.6462481021881104 seconds.\n",
      "pathSafeTimeString:  2019-05-02T16-00-00.000\n",
      "Uses           : 1594267 bytes\n",
      "Finished converting PFSS_OI after 3.2427361011505127 seconds.\n",
      "pathSafeTimeString:  2019-05-02T16-00-00.000\n",
      "Uses           : 1945979 bytes\n",
      "Finished converting SCS_OI after 3.998926877975464 seconds.\n",
      "pathSafeTimeString:  2019-05-02T20-00-00.000\n",
      "Uses           : 1600347 bytes\n",
      "Finished converting PFSS_OI after 4.5705530643463135 seconds.\n",
      "pathSafeTimeString:  2019-05-02T20-00-00.000\n",
      "Uses           : 1949803 bytes\n",
      "Finished converting SCS_OI after 5.302073955535889 seconds.\n",
      "Execution time for type sun_earth: 5.302259922027588 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "indices = [range(16200,16740), 'sun_earth']\n",
    "\n",
    "for timestamp in fitsfilesdates:\n",
    "    fitsfilesdates[timestamp].sort()\n",
    "    pfss_oi = fitsfilesdates[timestamp][1]\n",
    "    scs_oi = fitsfilesdates[timestamp][2]\n",
    "    toOsfls(pfss_oi[0], pfss_oi[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_oi[1],time.time()-start_time))\n",
    "    toOsfls(scs_oi[0], scs_oi[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(scs_oi[1],time.time()-start_time))\n",
    "        \n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
