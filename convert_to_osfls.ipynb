{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "\n",
    "fitsfiles = [] \n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles'):\n",
    "    for file in filenames:    \n",
    "        if(file.endswith('.fits')):\n",
    "            if('pfss_intoout' in file):\n",
    "                fitsfiles.append((dirpath + '/' + file, 'PFSS_IO'))\n",
    "            elif('pfss_outtoin' in file):\n",
    "                fitsfiles.append((dirpath + '/' + file, 'PFSS_OI'))\n",
    "            elif('scs_outtoin' in file):\n",
    "                fitsfiles.append((dirpath + '/' + file, 'SCS_OI'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Choose indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everynth(step):\n",
    "    return (range(0,16200, step), 'step' + str(step))\n",
    "\n",
    "indices = everynth(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defintion from OpenSpace function FieldlinesState::saveStateToOsfls\n",
    "    File is structured like this: (for version 0)\n",
    "    0. int                    - version number of binary state file! (in case something needs to be altered in the future, then increase CurrentVersion)\n",
    "    1. double                 - _triggerTime\n",
    "    2. int                    - _model\n",
    "    3. bool                   - _isMorphable\n",
    "    4. size_t                 - Number of lines in the state  == _lineStart.size() == _lineCount.size()\n",
    "    5. size_t                 - Total number of vertex points  == _vertexPositions.size() == _extraQuantities.size()\n",
    "    6. size_t                 - Number of extra quantites  == _extraQuantities.size() == _extraQuantityNames.size()\n",
    "    7. site_t                 - Number of total bytes that ALL _extraQuantityNames  consists of (Each such name is stored as a c_str which means it ends with the null char '\\0' )\n",
    "    8. std::vector<GLint>     - _lineStart\n",
    "    9. std::vector<GLsizei>   - _lineCount\n",
    "    10. std::vector<glm::vec3> - _vertexPositions\n",
    "    11. std::vector<float>     - _extraQuantities\n",
    "    12. array of c_str         - Strings naming the extra quantities (elements of _extraQuantityNames). Each string ends with null char '\\0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, numpy\n",
    "\n",
    "def sph2cart(coord):\n",
    "    return [\n",
    "         coord[2] * math.sin(coord[1]) * math.cos(coord[0]), \n",
    "         coord[2] * math.sin(coord[1]) * math.sin(coord[0]),\n",
    "         coord[2] * math.cos(coord[1])\n",
    "    ]\n",
    "\n",
    "def coord2datarow(coord):\n",
    "    sph = sph2cart(coord[0:3])\n",
    "    sph.append(coord[5])\n",
    "    return [numpy.float32(x) for x in sph] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Model(Enum):\n",
    "    Batsrus = 0\n",
    "    Enlil = 1\n",
    "    Pfss = 2\n",
    "    Wsa = 3\n",
    "    Invalid = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstimeToJ2000(ot):\n",
    "    timefits = ot[0:4] + '-' + ot[5:7] + '-' + ot[8:10] + 'T'\n",
    "    timefits += ot[11:13] + ot[14:17] + ot[18:21] + '.000'\n",
    "    pathSafeTimeString = timefits.replace(':', '-')\n",
    "    time = Time(timefits, format='fits')\n",
    "    y2000 = Time(2000, format='jyear')\n",
    "    jdaysdelta = time.jd - y2000.jd\n",
    "    jsecs = jdaysdelta*60*60*24\n",
    "    return [jsecs, pathSafeTimeString]\n",
    "\n",
    "fl_fits = fits.open(fitsfiles[11][0])\n",
    "obstimeToJ2000(fl_fits[0].header['OBSTIME'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import struct, ctypes\n",
    "\n",
    "def toOsfls(filename, modelname, indices,  typename):\n",
    "    fl_fits = fits.open(filename)\n",
    "    fl_data = fl_fits[0].data\n",
    "    fl_fits.close()\n",
    "    versionNumber = 0\n",
    "    [triggerTime, pathSafeTimeString] = obstimeToJ2000(fl_fits[0].header['OBSTIME'])\n",
    "    #print(\"TriggerTime: \",triggerTime)\n",
    "    print(\"pathSafeTimeString: \",pathSafeTimeString)\n",
    "    fileName = pathSafeTimeString + '.osfls'\n",
    "\n",
    "    model = Model.Wsa.value\n",
    "    isMorphable = False\n",
    "\n",
    "    nVert = 0\n",
    "    lineStart = []\n",
    "    lineCount = []\n",
    "    vertexPositions = []\n",
    "    extraQuantities = []\n",
    "\n",
    "    for i in indices:\n",
    "        points = [coord2datarow(pt) for pt in fl_data[i] if pt[0] > -900] \n",
    "        if (len(points) < 2): continue\n",
    "        lineStart.append(nVert)\n",
    "        nVert += len(points)\n",
    "        lineCount.append(len(points))\n",
    "        [vertexPositions.extend(pt[0:3]) for pt in points] # extend to unfold elements\n",
    "        [extraQuantities.append(pt[3]) for pt in points]\n",
    "\n",
    "    nLines = len(lineStart)\n",
    "\n",
    "    nExtras = 1\n",
    "    extraQuantityNames = ['polarity \\0']\n",
    "    nStringBytes = sum([len(s) for s in extraQuantityNames])\n",
    "    allNamesInOne = ''\n",
    "    for s in extraQuantityNames:\n",
    "        allNamesInOne += s\n",
    "    \n",
    "    # Prepare data for writing to binary. Using Struct and pack\n",
    "    typestr = '= i d i ? Q Q Q Q %sl %sL %sf %sf %ss' % (nLines, nLines, 3*nVert, nVert, nStringBytes)\n",
    "    struct_to_write = struct.Struct(typestr)\n",
    "    #print('Format string  :', struct_to_write.format)\n",
    "    print('Uses           :', struct_to_write.size, 'bytes')\n",
    "    values_to_write = (versionNumber, triggerTime, model, isMorphable, nLines, nVert, nExtras, nStringBytes)\n",
    "    values_to_write += (*lineStart, *lineCount, *vertexPositions, *extraQuantities, allNamesInOne.encode('utf-8'))\n",
    "    \n",
    "    buffer = ctypes.create_string_buffer(struct_to_write.size)    \n",
    "    struct_to_write.pack_into(buffer, 0, *values_to_write)\n",
    "    \n",
    "    fout = open('./' + modelname + '/' + typename + '_' + fileName, 'wb')\n",
    "    fout.write(buffer)\n",
    "    fout.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make into osfls format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "for fitsfile in fitsfiles:\n",
    "    toOsfls(fitsfile[0], fitsfile[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(fitsfile[0],time.time()-start_time))\n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick closed field lines from PFSS_IO\n",
    "By removing the open ones. Opens ones are defined by their first and last point having the same polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickClosed(filename):\n",
    "    fl_fits = fits.open(filename)\n",
    "    fl_data = fl_fits[0].data\n",
    "\n",
    "    indices_to_save = []\n",
    "\n",
    "    for i in range(16200):\n",
    "        b_radii = [pt[5] for pt in fl_data[i] if pt[0] > -900] \n",
    "        if (len(b_radii) < 2): continue\n",
    "        first_b_radius = b_radii[0]\n",
    "        last_b_radius = b_radii[-1]\n",
    "        if(first_b_radius*last_b_radius < 0): #if product is negative/opposite signs\n",
    "            indices_to_save.append(i)\n",
    "    return indices_to_save\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pfss_io closed lines sparser\n",
    "def make_sparser(indices, step):\n",
    "    new_indices = indices[::3]\n",
    "    return [new_indices, 'closed_step' + str(step)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick boundary lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def boundaryLines(filename_io, filename_oi, indices_closed):\n",
    "    fl_io = (fits.open(filename_io))[0].data\n",
    "    fl_oi = (fits.open(filename_oi))[0].data\n",
    "\n",
    "    threshold = math.sqrt(2)\n",
    "    # boundary_lines_io = [] do we want these?\n",
    "    boundary_lines_oi = []\n",
    "    io_last_phi = {}\n",
    "    io_last_theta = {}\n",
    "    io_first_phi = {}\n",
    "    io_first_theta = {}\n",
    "\n",
    "    for j in indices_closed:\n",
    "        last = -1 # find last index\n",
    "        for point in fl_io[j]:\n",
    "            if (point[0] > -900):\n",
    "                last += 1\n",
    "            else: break\n",
    "        # get the first and last coordinates for in-to-out (both on surface)\n",
    "        io_last_phi[j] = math.degrees(fl_io[j][last][0])\n",
    "        io_last_theta[j] = math.degrees(fl_io[j][last][1])\n",
    "        io_first_phi[j] = math.degrees(fl_io[j][0][0])\n",
    "        io_first_theta[j] = math.degrees(fl_io[j][0][1])\n",
    "\n",
    "    for i in range(16200):\n",
    "        last = -1\n",
    "        for point in fl_oi[i]:\n",
    "            if (point[0] > -900):\n",
    "                last += 1\n",
    "            else: break\n",
    "        if (last < 2): continue\n",
    "        # get the last coordinates for out-to-in (the ones on the surface)\n",
    "        oi_last_phi = math.degrees(fl_oi[i][last][0])\n",
    "        oi_last_theta = math.degrees(fl_oi[i][last][1])\n",
    "        for j in indices_closed:\n",
    "            # calculate distances and compare\n",
    "            dist_last_phi = abs(io_last_phi[j] - oi_last_phi)\n",
    "            dist_last_theta = abs(io_last_theta[j] - oi_last_theta)\n",
    "            dist_first_phi = abs(io_first_phi[j] - oi_last_phi)\n",
    "            dist_first_theta = abs(io_first_theta[j] - oi_last_theta)\n",
    "            if(dist_last_phi < threshold and dist_last_theta < threshold):\n",
    "                #boundary_lines_io.append(j)\n",
    "                boundary_lines_oi.append(i)\n",
    "                break\n",
    "            if(dist_first_phi < threshold and dist_first_theta < threshold):\n",
    "                #boundary_lines_io.append(j)\n",
    "                boundary_lines_oi.append(i)\n",
    "                break\n",
    "    return [boundary_lines_oi, 'boundary']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fitsfilesdates = {} \n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles'):\n",
    "    for file in filenames:    \n",
    "        if(file.endswith('.fits')):\n",
    "            date = file[0:12]\n",
    "            if(date not in fitsfilesdates):\n",
    "                fitsfilesdates[date] = []\n",
    "            if('pfss_intoout' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'PFSS_IO'))\n",
    "            elif('pfss_outtoin' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'PFSS_OI'))\n",
    "            elif('scs_outtoin' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'SCS_OI'))\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run allake into osfls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "# relies heavily on having a sorted list of files for each timestep\n",
    "# so that pfss_io goes first and picks out the lines\n",
    "for timestamp in fitsfilesdates:\n",
    "    fitsfilesdates[timestamp].sort()\n",
    "    pfss_io = fitsfilesdates[timestamp][0]\n",
    "    pfss_oi = fitsfilesdates[timestamp][1]\n",
    "    scs_oi = fitsfilesdates[timestamp][2]\n",
    "    indices_closed_lines = pickClosed(pfss_io[0])\n",
    "    print('Picked closed lines for {} after {} seconds.'.format(timestamp,time.time()-start_time))\n",
    "    indices = make_sparser(indices_closed_lines, 3)\n",
    "    toOsfls(pfss_io[0], pfss_io[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_io[1],time.time()-start_time))\n",
    "    indices = boundaryLines(pfss_io[0], pfss_oi[0], indices_closed_lines)\n",
    "    print('Picked boundary lines after {} seconds.'.format(time.time()-start_time))\n",
    "    toOsfls(pfss_oi[0], pfss_oi[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_oi[1],time.time()-start_time))\n",
    "    toOsfls(scs_oi[0], scs_oi[1], indices[0], indices[1])\n",
    "    print('Finished converting {} after {} seconds.'.format(scs_oi[1],time.time()-start_time))\n",
    "        \n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
