{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Populate file list based on timestamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import walk\n",
    "fitsfilesdates = {} \n",
    "\n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles'):\n",
    "    for file in filenames:    \n",
    "        if(file.endswith('.fits')):\n",
    "            date = file[0:12]\n",
    "            if(date not in fitsfilesdates):\n",
    "                fitsfilesdates[date] = []\n",
    "            if('pfss_intoout' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'PFSS_IO'))\n",
    "            elif('pfss_outtoin' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'PFSS_OI'))\n",
    "            elif('scs_outtoin' in file):\n",
    "                fitsfilesdates[date].append((dirpath + '/' + file, 'SCS_OI'))\n",
    "    break\n",
    "    \n",
    "for l in fitsfilesdates:\n",
    "    fitsfilesdates[l].sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "velfilesdates = {}\n",
    "wsafilesdates = {}\n",
    "for (dirpath, dirnames, filenames) in walk('./fitsfiles_images'):\n",
    "    for file in filenames:    \n",
    "        if('vel' in file):\n",
    "            date = file[4:16]\n",
    "            velfilesdates[date] = dirpath + '/' + file\n",
    "        if('wsa' in file):\n",
    "            date = file[4:16]\n",
    "            wsafilesdates[date] = dirpath + '/' + file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function definitions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, numpy\n",
    "\n",
    "def sph2cart(coord):\n",
    "    return [\n",
    "         coord[2] * math.sin(coord[1]) * math.cos(coord[0]), \n",
    "         coord[2] * math.sin(coord[1]) * math.sin(coord[0]),\n",
    "         coord[2] * math.cos(coord[1])\n",
    "    ]\n",
    "\n",
    "def coord2datarow(coord):\n",
    "    sph = sph2cart(coord[0:3])\n",
    "    sph.append(coord[5])\n",
    "    return [numpy.float32(x) for x in sph] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from enum import Enum\n",
    "class Model(Enum):\n",
    "    Batsrus = 0\n",
    "    Enlil = 1\n",
    "    Pfss = 2\n",
    "    Wsa = 3\n",
    "    Invalid = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obstimeToJ2000(ot):\n",
    "    timefits = ot[0:4] + '-' + ot[5:7] + '-' + ot[8:10] + 'T'\n",
    "    timefits += ot[11:13] + ot[14:17] + ot[18:21] + '.000'\n",
    "    pathSafeTimeString = timefits.replace(':', '-')\n",
    "    time = Time(timefits, format='fits')\n",
    "    y2000 = Time(2000, format='jyear')\n",
    "    jdaysdelta = time.jd - y2000.jd\n",
    "    jsecs = jdaysdelta*60*60*24\n",
    "    return [jsecs, pathSafeTimeString]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from astropy.io import fits\n",
    "from astropy.time import Time\n",
    "import struct, ctypes, math\n",
    "\n",
    "def toOsfls(filename, modelname, indices,  typename, xq_filename = \"\"):\n",
    "    fl_fits = fits.open(filename)\n",
    "    fl_data = fl_fits[0].data\n",
    "    fl_fits.close()\n",
    "    \n",
    "    # if no extra arg given, it's the last 540\n",
    "    if(xq_filename == \"\"):\n",
    "        print(\"sun-earth connection\")\n",
    "    # read file for extra quantity\n",
    "    elif(modelname == 'PFSS_IO'):\n",
    "        wsa_fits = fits.open(xq_filename)\n",
    "        wsa_data = wsa_fits[0].data\n",
    "        wsa_data = wsa_data[6] # the seventh layer has the open(>=1)/closedness(0)\n",
    "        wsa_fits.close()\n",
    "    else:\n",
    "        vel_fits = fits.open(xq_filename)\n",
    "        vel_data = vel_fits[0].data\n",
    "        vel_data = vel_data[1] # the second layer has the wind speed\n",
    "        vel_fits.close()\n",
    "        \n",
    "    \n",
    "    \n",
    "    versionNumber = 0\n",
    "    [triggerTime, pathSafeTimeString] = obstimeToJ2000(fl_fits[0].header['OBSTIME'])\n",
    "    #print(\"TriggerTime: \",triggerTime)\n",
    "    print(\"pathSafeTimeString: \",pathSafeTimeString)\n",
    "    fileName = pathSafeTimeString + '.osfls'\n",
    "\n",
    "    model = Model.Wsa.value\n",
    "    isMorphable = False\n",
    "\n",
    "    nVert = 0\n",
    "    lineStart = []\n",
    "    lineCount = []\n",
    "    vertexPositions = []\n",
    "    extraQuantities = []\n",
    "\n",
    "    for i in indices:\n",
    "        points = [coord2datarow(pt) for pt in fl_data[i] if pt[0] > -900] \n",
    "        if (len(points) < 2): continue\n",
    "        lineStart.append(nVert)\n",
    "        nVert += len(points)\n",
    "        lineCount.append(len(points))\n",
    "        [vertexPositions.extend(pt[0:3]) for pt in points] # extend to unfold elements\n",
    "        if(xq_filename == \"\"):\n",
    "            sunearthpoint = -1\n",
    "            if(i in range(16200, 16380)):\n",
    "                sunearthpoint = 0\n",
    "            elif (i in range(16380, 16560)):\n",
    "                sunearthpoint = 1\n",
    "            elif (i in range(16560, 16740)):\n",
    "                sunearthpoint = 2\n",
    "            xtra = [sunearthpoint]*len(points) # same value for all points\n",
    "            extraQuantities.extend(xtra)\n",
    "        elif(modelname == 'PFSS_IO'):\n",
    "            #[extraQuantities.append(pt[3]) for pt in points]\n",
    "            openness = wsa_data[math.floor(i/180)][i%180]\n",
    "            xtra = [openness]*len(points) # same value for all points\n",
    "            extraQuantities.extend(xtra)\n",
    "        else:     \n",
    "            velocity = vel_data[math.floor(i/180)][i%180]\n",
    "            if(points[0][3] < 0): velocity = -1*velocity\n",
    "            xtra = [velocity]*len(points) # same value for all points\n",
    "            extraQuantities.extend(xtra)\n",
    "    \n",
    "    nLines = len(lineStart)\n",
    "\n",
    "    nExtras = 1\n",
    "    if(xq_filename == \"\"):\n",
    "        extraQuantityNames = ['sun-earth level \\0']\n",
    "    elif(modelname == 'PFSS_IO'):\n",
    "        extraQuantityNames = ['open/closed regions \\0']\n",
    "    else: \n",
    "        extraQuantityNames = ['wind speed with polarity \\0']\n",
    "    nStringBytes = sum([len(s) for s in extraQuantityNames])\n",
    "    allNamesInOne = ''\n",
    "    for s in extraQuantityNames:\n",
    "        allNamesInOne += s\n",
    "    \n",
    "    # Prepare data for writing to binary. Using Struct and pack\n",
    "    typestr = '= i d i ? Q Q Q Q %sl %sL %sf %sf %ss' % (nLines, nLines, 3*nVert, nExtras*nVert, nStringBytes)\n",
    "    struct_to_write = struct.Struct(typestr)\n",
    "    #print('Format string  :', struct_to_write.format)\n",
    "    print('Uses           :', struct_to_write.size, 'bytes')\n",
    "    values_to_write = (versionNumber, triggerTime, model, isMorphable, nLines, nVert, nExtras, nStringBytes)\n",
    "    values_to_write += (*lineStart, *lineCount, *vertexPositions, *extraQuantities, allNamesInOne.encode('utf-8'))\n",
    "    \n",
    "    buffer = ctypes.create_string_buffer(struct_to_write.size)    \n",
    "    struct_to_write.pack_into(buffer, 0, *values_to_write)\n",
    "    \n",
    "    fout = open('./' + modelname + '/' + typename + '_' + fileName, 'wb')\n",
    "    fout.write(buffer)\n",
    "    fout.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def everynth(step):\n",
    "    return (range(0,16200, step), 'step' + str(step))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Only PFSS_IO, every nth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# relies heavily on having a sorted list of files for each timestep\n",
    "# so that pfss_io goes first and picks out the lines\n",
    "for timestamp in fitsfilesdates:\n",
    "    pfss_io = fitsfilesdates[timestamp][0]\n",
    "    indices = everynth(13) # change step size here\n",
    "    toOsfls(pfss_io[0], pfss_io[1], indices[0], indices[1], wsafilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_io[1],time.time()-start_time))\n",
    "    \n",
    "        \n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick closed field lines from PFSS_IO\n",
    "By removing the open ones. Opens ones are defined by their first and last point having the same polarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pickClosed(filename):\n",
    "    fl_fits = fits.open(filename)\n",
    "    fl_data = fl_fits[0].data\n",
    "\n",
    "    indices_to_save = []\n",
    "\n",
    "    for i in range(16200):\n",
    "        b_radii = [pt[5] for pt in fl_data[i] if pt[0] > -900] \n",
    "        if (len(b_radii) < 2): continue\n",
    "        first_b_radius = b_radii[0]\n",
    "        last_b_radius = b_radii[-1]\n",
    "        if(first_b_radius*last_b_radius < 0): #if product is negative/opposite signs\n",
    "            indices_to_save.append(i)\n",
    "    return indices_to_save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make a pfss_io closed lines sparser\n",
    "def make_sparser(indices, step):\n",
    "    new_indices = indices[::3]\n",
    "    return [new_indices, 'closed_step' + str(step)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick boundary lines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def boundaryLines(filename_io, filename_oi, indices_closed):\n",
    "    fl_io = (fits.open(filename_io))[0].data\n",
    "    fl_oi = (fits.open(filename_oi))[0].data\n",
    "\n",
    "    threshold = math.sqrt(2)\n",
    "    # boundary_lines_io = [] do we want these?\n",
    "    boundary_lines_oi = []\n",
    "    io_last_phi = {}\n",
    "    io_last_theta = {}\n",
    "    io_first_phi = {}\n",
    "    io_first_theta = {}\n",
    "\n",
    "    for j in indices_closed:\n",
    "        last = -1 # find last index\n",
    "        for point in fl_io[j]:\n",
    "            if (point[0] > -900):\n",
    "                last += 1\n",
    "            else: break\n",
    "        # get the first and last coordinates for in-to-out (both on surface)\n",
    "        io_last_phi[j] = math.degrees(fl_io[j][last][0])\n",
    "        io_last_theta[j] = math.degrees(fl_io[j][last][1])\n",
    "        io_first_phi[j] = math.degrees(fl_io[j][0][0])\n",
    "        io_first_theta[j] = math.degrees(fl_io[j][0][1])\n",
    "\n",
    "    for i in range(16200):\n",
    "        last = -1\n",
    "        for point in fl_oi[i]:\n",
    "            if (point[0] > -900):\n",
    "                last += 1\n",
    "            else: break\n",
    "        if (last < 2): continue\n",
    "        # get the last coordinates for out-to-in (the ones on the surface)\n",
    "        oi_last_phi = math.degrees(fl_oi[i][last][0])\n",
    "        oi_last_theta = math.degrees(fl_oi[i][last][1])\n",
    "        for j in indices_closed:\n",
    "            # calculate distances and compare\n",
    "            dist_last_phi = abs(io_last_phi[j] - oi_last_phi)\n",
    "            dist_last_theta = abs(io_last_theta[j] - oi_last_theta)\n",
    "            dist_first_phi = abs(io_first_phi[j] - oi_last_phi)\n",
    "            dist_first_theta = abs(io_first_theta[j] - oi_last_theta)\n",
    "            if(dist_last_phi < threshold and dist_last_theta < threshold):\n",
    "                #boundary_lines_io.append(j)\n",
    "                boundary_lines_oi.append(i)\n",
    "                break\n",
    "            if(dist_first_phi < threshold and dist_first_theta < threshold):\n",
    "                #boundary_lines_io.append(j)\n",
    "                boundary_lines_oi.append(i)\n",
    "                break\n",
    "    return [boundary_lines_oi, 'boundary']\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fillOut(boundary_indices, step):\n",
    "    output = []\n",
    "    previous_index = 0\n",
    "    for index in boundary_indices:\n",
    "        subrange = list(range(previous_index, index, step))\n",
    "        output.extend(subrange)\n",
    "        if(output[-1] != index):    \n",
    "            output.append(index)\n",
    "        previous_index = index\n",
    "    return [output, 'boundary_filled']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make into osfls - closed lines and boundary lines with fillers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "# relies heavily on having a sorted list of files for each timestep\n",
    "# so that pfss_io goes first and picks out the lines\n",
    "for timestamp in fitsfilesdates:\n",
    "    pfss_io = fitsfilesdates[timestamp][0]\n",
    "    pfss_oi = fitsfilesdates[timestamp][1]\n",
    "    scs_oi = fitsfilesdates[timestamp][2]\n",
    "    indices_closed_lines = pickClosed(pfss_io[0])\n",
    "    print('Picked closed lines for {} after {} seconds.'.format(timestamp,time.time()-start_time))\n",
    "    indices = make_sparser(indices_closed_lines, 3) # change here for sparser\n",
    "    #toOsfls(pfss_io[0], pfss_io[1], indices[0], indices[1], wsafilesdates[timestamp])\n",
    "    #print('Finished converting {} after {} seconds.'.format(pfss_io[1],time.time()-start_time))\n",
    "    indices = boundaryLines(pfss_io[0], pfss_oi[0], indices_closed_lines)\n",
    "    indices = fillOut(indices[0], 25) # change step here for sparser\n",
    "    print('Picked boundary lines after {} seconds.'.format(time.time()-start_time))\n",
    "    toOsfls(pfss_oi[0], pfss_oi[1], indices[0], indices[1], velfilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(pfss_oi[1],time.time()-start_time))\n",
    "    toOsfls(scs_oi[0], scs_oi[1], indices[0], indices[1], velfilesdates[timestamp])\n",
    "    print('Finished converting {} after {} seconds.'.format(scs_oi[1],time.time()-start_time))\n",
    "        \n",
    "print(\"Execution time for type {}: {} seconds\".format(indices[1], time.time()-start_time))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pick the last 540 (sun-earth connection)\n",
    "And turn OI sets to osfls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mergeAndConvertToOsfls(filenamePFSS, filenameSCS):\n",
    "    fl_fits_pfss = fits.open(filenamePFSS)\n",
    "    fl_data_pfss = fl_fits_pfss[0].data\n",
    "    fl_fits_pfss.close()\n",
    "    \n",
    "    fl_fits_scs = fits.open(filenameSCS)\n",
    "    fl_data_scs = fl_fits_scs[0].data\n",
    "    fl_fits_scs.close()\n",
    "    \n",
    "    indices = range(16200,16740)\n",
    "\n",
    "    print(\"sun-earth connection\")\n",
    "        \n",
    "    \n",
    "    [triggerTime, pathSafeTimeString] = obstimeToJ2000(fl_fits_pfss[0].header['OBSTIME'])\n",
    "    [triggerTime_s, pathSafeTimeString_s] = obstimeToJ2000(fl_fits_scs[0].header['OBSTIME'])\n",
    "    if(triggerTime != triggerTime_s):\n",
    "        print(\"Files are from different times. Canceling conversion. triggertimes: \")\n",
    "        print(triggerTime)\n",
    "        print(triggerTime_s)\n",
    "        \n",
    "    versionNumber = 0\n",
    "    fileName = pathSafeTimeString + '.osfls'\n",
    "    model = Model.Wsa.value\n",
    "    isMorphable = False\n",
    "    \n",
    "    nVert = 0\n",
    "    lineStart = []\n",
    "    lineCount = []\n",
    "    vertexPositions = []\n",
    "    extraQuantities = []\n",
    "    \n",
    "    extraQuantities_polarity = []\n",
    "    extraQuantities_level = []\n",
    "\n",
    "    for i in indices:\n",
    "        points_pfss = [coord2datarow(pt) for pt in fl_data_pfss[i] if pt[0] > -900] \n",
    "        points_scs = [coord2datarow(pt) for pt in fl_data_scs[i] if pt[0] > -900] \n",
    "        \n",
    "        if (len(points_pfss) < 2 or len(points_scs) < 2): continue\n",
    "            \n",
    "        lineStart.append(nVert)\n",
    "        \n",
    "        combinedVertLen = (len(points_pfss) + len(points_scs))\n",
    "        nVert += combinedVertLen\n",
    "        lineCount.append(combinedVertLen)\n",
    "        \n",
    "        [vertexPositions.extend(pt[0:3]) for pt in points_scs] # add scs vertices FIRST\n",
    "        [vertexPositions.extend(pt[0:3]) for pt in points_pfss] # add pfss vertices\n",
    "        \n",
    "        \n",
    "        # The following methods does not really work if you want to mask away a layer of lines\n",
    "        #polarity = 0\n",
    "        #if(points_scs[0][0] >= 0):\n",
    "        #    polarity = 4\n",
    "        #sunearthpoint = 3\n",
    "        #if (i in range(16380, 16560)):\n",
    "        #    sunearthpoint = 1\n",
    "        #elif (i in range(16560, 16740)):\n",
    "        #    sunearthpoint = 3\n",
    "        \n",
    "        # middle section of point density is colored by polarity\n",
    "        #quarter = int(combinedVertLen/4)\n",
    "        #mid = combinedVertLen - (2*quarter)\n",
    "        #xtra = [sunearthpoint]*quarter # use sun eart level category for ends of fieldline\n",
    "        #xtra.extend([polarity]*mid) # use polarity for middle of fieldline\n",
    "        #xtra.extend([sunearthpoint]*quarter)\n",
    "        \n",
    "        # color rings (based on radius) of polarity on line set\n",
    "        #xtra = []     \n",
    "        #for point in fl_data_scs[i]:\n",
    "        #    if(point[0] < -900): continue\n",
    "        #    if(math.floor(point[2])%2 != 0 or point[2] >19): #if even or above 19 solar radii\n",
    "        #        xtra.append(sunearthpoint)\n",
    "        #    else:\n",
    "        #        xtra.append(polarity)\n",
    "        #for point in fl_data_pfss[i]:\n",
    "        #    if(point[0] < -900): continue\n",
    "        #    if(math.floor(point[2])%2 != 0 ): #if even\n",
    "        #        xtra.append(sunearthpoint)\n",
    "        #    else:\n",
    "        #        xtra.append(polarity)\n",
    "        \n",
    "        polarity = 0\n",
    "        if(points_scs[0][0] >= 0):\n",
    "            polarity = 1\n",
    "        xtra = [polarity]*combinedVertLen\n",
    "        extraQuantities_polarity.extend(xtra)\n",
    "        \n",
    "        sunearthpoint = 1\n",
    "        if (i in range(16380, 16560)):\n",
    "            sunearthpoint = 0\n",
    "        elif (i in range(16560, 16740)):\n",
    "            sunearthpoint = 2\n",
    "        xtra = [sunearthpoint]*combinedVertLen\n",
    "        extraQuantities_level.extend(xtra)\n",
    "       \n",
    "    nLines = len(lineStart)\n",
    "\n",
    "    nExtras = 2\n",
    "    extraQuantities = extraQuantities_polarity\n",
    "    extraQuantities.extend(extraQuantities_level)\n",
    "\n",
    "    extraQuantityNames = ['polarity \\0', 'sun-earth level\\0']\n",
    "\n",
    "    nStringBytes = sum([len(s) for s in extraQuantityNames])\n",
    "    allNamesInOne = ''\n",
    "    for s in extraQuantityNames:\n",
    "        allNamesInOne += s\n",
    "    \n",
    "    # Prepare data for writing to binary. Using Struct and pack\n",
    "    typestr = '= i d i ? Q Q Q Q %sl %sL %sf %sf %ss' % (nLines, nLines, 3*nVert, nExtras*nVert, nStringBytes)\n",
    "    struct_to_write = struct.Struct(typestr)\n",
    "    #print('Format string  :', struct_to_write.format)\n",
    "    print('Uses           :', struct_to_write.size, 'bytes')\n",
    "    values_to_write = (versionNumber, triggerTime, model, isMorphable, nLines, nVert, nExtras, nStringBytes)\n",
    "    values_to_write += (*lineStart, *lineCount, *vertexPositions, *extraQuantities, allNamesInOne.encode('utf-8'))\n",
    "    \n",
    "    buffer = ctypes.create_string_buffer(struct_to_write.size)    \n",
    "    struct_to_write.pack_into(buffer, 0, *values_to_write)\n",
    "    \n",
    "    fout = open('./SUN-EARTH/sun-earth-comb_' + fileName, 'wb')\n",
    "    fout.write(buffer)\n",
    "    fout.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "start_time = time.time()\n",
    "\n",
    "for timestamp in fitsfilesdates:\n",
    "    pfss_oi = fitsfilesdates[timestamp][1]\n",
    "    scs_oi = fitsfilesdates[timestamp][2]\n",
    "    mergeAndConvertToOsfls(pfss_oi[0], scs_oi[0])       \n",
    "print(\"Execution time for type sun earth: {} seconds\".format(time.time()-start_time))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
